{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62df1195-d33b-43d9-a9e5-4254c59e3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9db43e-4584-4191-969d-3f3a44bcf9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632dd480-e466-4fd8-83df-adbf2d550daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(18)\n",
      "Action space size: 18\n",
      "Observation space shape: (84, 84, 1)\n",
      "Environment spec:  EnvSpec(id='ALE/MarioBros-v5', entry_point='shimmy.atari_env:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'game': 'mario_bros', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4, 'max_num_frames_per_episode': 108000, 'mode': 4}, namespace='ALE', name='MarioBros', version=5, additional_wrappers=(WrapperSpec(name='ProcessFrame84', entry_point='agent_model:ProcessFrame84', kwargs=None), WrapperSpec(name='ScaledFloatFrame', entry_point='agent_model:ScaledFloatFrame', kwargs=None)), vector_entry_point=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "GAME = \"ALE/MarioBros-v5\"\n",
    "\n",
    "#Make environment\n",
    "env = agent_model.make_env(gym.make(GAME, mode=4))\n",
    "print(\"Action space: {}\".format(env.action_space))\n",
    "print(\"Action space size: {}\".format(env.action_space.n))\n",
    "observation, info = env.reset()\n",
    "print(\"Observation space shape: {}\".format(observation.shape))\n",
    "print(\"Environment spec: \", env.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24edc58f-1454-44d0-97c0-8c8b23ccce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 84, 1]\n",
      "[84, 84, 1]\n",
      "run:  5\n",
      "*********\n",
      "Episode 100 (Step 23786) - Moving Avg Reward: -0.490 Loss: 0.00538 Epsilon: 0.884 Avg Steps per Episode: 751.0\n",
      "*********\n",
      "Episode 110 (Step 29819) - Moving Avg Reward: -0.690 Loss: 0.01004 Epsilon: 0.856 Avg Steps per Episode: 603.3\n",
      "*********\n",
      "Episode 120 (Step 35227) - Moving Avg Reward: -0.790 Loss: 0.01739 Epsilon: 0.825 Avg Steps per Episode: 540.8\n",
      "*********\n",
      "Episode 130 (Step 41046) - Moving Avg Reward: -0.740 Loss: 0.01193 Epsilon: 0.798 Avg Steps per Episode: 581.9\n",
      "*********\n",
      "Episode 140 (Step 46885) - Moving Avg Reward: -0.710 Loss: 0.01360 Epsilon: 0.769 Avg Steps per Episode: 583.9\n",
      "*********\n",
      "Episode 150 (Step 53505) - Moving Avg Reward: -0.673 Loss: 0.01311 Epsilon: 0.734 Avg Steps per Episode: 662.0\n",
      "***"
     ]
    }
   ],
   "source": [
    "# Traing the agent\n",
    "agent = agent_model.Agent(env, gamma=0.999, batch_size=64, lr=0.0007, max_episodes=1000,\n",
    "              max_steps_per_episode=2000,\n",
    "              steps_until_sync=20, choose_action_frequency=1,\n",
    "              pre_train_steps = 10, final_exploration_step = 200_000)\n",
    "agent.load_weights(\"./checkpoints_v5/ep_90\")\n",
    "agent.train(start_ep=91, start_step=16276, eps_until_save=10)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6407b-b1be-4773-9899-77a96b7276b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "env = agent_model.make_env(gym.make(GAME, mode=4, render_mode=\"rgb_array\"))\n",
    "observation, info = env.reset()\n",
    "\n",
    "# create a VideoWriter object.\n",
    "video_fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_writer = cv2.VideoWriter('./output_videos/test_output_' + str(datetime.datetime.now()) + '.avi', -1, 20.0, (160, 210), isColor=True)\n",
    "\n",
    "#show the steps the agent takes using the optimal policy table\n",
    "for i in range(2):\n",
    "    observation, info = env.reset()\n",
    "    terminated = truncated = False\n",
    "    rewards = 0\n",
    "    while not terminated and not truncated:\n",
    "        #find max policy\n",
    "        Q_values = agent.predict_q(np.expand_dims(observation, axis=0))\n",
    "        action = np.argmax(Q_values[0])\n",
    "        \n",
    "        num_lives = info[\"lives\"]\n",
    "            \n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        reward /= 800\n",
    "        if info[\"lives\"] < num_lives: # penalize agent when life lost\n",
    "            reward -= 0.33\n",
    "                    \n",
    "        video_writer.write(cv2.cvtColor(np.uint8(np.reshape(env.render(), (210, 160, 3))), cv2.COLOR_RGB2BGR))\n",
    "        rewards += reward\n",
    "    print('Total reward is: '+str(rewards))\n",
    "env.close()\n",
    "\n",
    "# Close the VideoWriter object.\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae564e-7d08-4e0a-80b8-18031f1e80ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
